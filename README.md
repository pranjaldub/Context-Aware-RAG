# Context-Aware-RAG

# ğŸ§  Conversational RAG â€” Context-Aware Retrieval-Augmented Generation

[![Python](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/)
[![LangChain](https://img.shields.io/badge/langchain-%F0%9F%A4%96-green)](https://docs.langchain.com/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--3.5/4-blueviolet)](https://openai.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> A LangChain-powered framework to build multi-turn, memory-enhanced conversational agents using Retrieval-Augmented Generation (RAG).

---

## ğŸ¯ Project Objective

Traditional RAG systems treat each user query as independent. **Conversational RAG** takes it further by integrating **memory**, **contextual input rephrasing**, and **session persistence**, enabling your AI assistant to understand follow-ups and maintain coherent conversations.

---

## ğŸ§© Features

- âœ… **Basic RAG Setup** â€” Vector store (Chroma), LLM (OpenAI), prompt template
- ğŸ¤– **Chat History Awareness** â€” Understands and reformulates follow-up questions using chat memory
- ğŸ”„ **Contextual Retrieval** â€” Uses `create_history_aware_retriever` to fetch better context
- ğŸ§  **Session Memory** â€” Tracks and persists conversations across user sessions using LangChainâ€™s `RunnableWithMessageHistory`
- ğŸ’¾ **.env Config** â€” Secure and flexible API key storage using `python-dotenv`

---

## ğŸ› ï¸ Tech Stack

- Python 3.11.4 (`pyenv`, `poetry`)
- [LangChain](https://github.com/langchain-ai/langchain)
- [ChromaDB](https://www.trychroma.com/) for vector storage
- [OpenAI](https://platform.openai.com/) models (GPT-3.5/4)
- Jupyter Lab / VS Code
- `python-dotenv` for environment variables

---

## ğŸ“ Project Structure

â”œâ”€â”€ data/
â”‚ â””â”€â”€ be-good.txt # Sample text file to index and query
â”œâ”€â”€ .env.example # Environment variables template
â”œâ”€â”€ 001-conversational-rag.py # Full RAG implementation script
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ tutorial.ipynb # Jupyter notebook walkthrough
â”œâ”€â”€ README.md # This file
â””â”€â”€ requirements.txt / pyproject.toml





---

## âš™ï¸ Setup Instructions

### ğŸ Python Environment

```bash
git clone https://github.com/yourusername/conversational-rag.git
cd conversational-rag
pyenv local 3.11.4
poetry install
poetry shell


ğŸ” API Keys
Rename .env.example to .env

Add the following keys:

OPENAI_API_KEY=your_openai_api_key
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=your_langchain_api_key
LANGCHAIN_PROJECT=001-conversational-rag



ğŸš€ Running the Project
â–¶ï¸ From Notebook
bash
Copy code
jupyter lab
Open the tutorial notebook and run step-by-step.

â–¶ï¸ From VS Code / Terminal
bash
Copy code
python 001-conversational-rag.py
ğŸ§  How It Works
Step 1: Basic RAG â€” Use OpenAI + ChromaDB to answer questions from documents.

Step 2: Contextual Prompt â€” Create a ChatPromptTemplate that rewrites ambiguous user queries.

Step 3: History-Aware Retriever â€” Build a retriever that factors in previous chat turns.

Step 4: Conversational RAG Chain â€” Integrate chat memory using MessagesPlaceholder.

Step 5: Persistence â€” Use RunnableWithMessageHistory to track sessions (like session_id = "001").

ğŸ’¡ Use Cases
Chatbots that understand follow-up queries

Context-aware customer support

Conversational document Q&A

AI agents with long-term memory

ğŸ“œ License
This project is licensed under the MIT License - see the LICENSE file for details.

ğŸ™Œ Acknowledgements
Built using:

LangChain

OpenAI

Chroma Vector Store

ğŸ“¬ Contact
For suggestions, questions, or feedback: your-email@example.com

vbnet
Copy code

Let me know if youâ€™d like me to:
- Add Markdown rendering of architecture diagrams.
- Create a walkthrough GIF/demo.
- Publish it to HuggingFace Spaces or Streamlit.

Just drop the project folder name and GitHub repo name if you'd like it cu
